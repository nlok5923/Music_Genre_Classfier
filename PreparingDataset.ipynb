{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " processing {} genre_dataset_reduced\\pop\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'expected_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9aca4c3c15a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0msave_mfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mJSON_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_segments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-9aca4c3c15a5>\u001b[0m in \u001b[0;36msave_mfcc\u001b[1;34m(dataset_path, json_path, n_mfcc, n_fft, hop_length, num_segments)\u001b[0m\n\u001b[0;32m     62\u001b[0m                                                )\n\u001b[0;32m     63\u001b[0m                     \u001b[0mmfcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_num\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmfcc_vectors_per_segment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mfcc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'expected_num' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import math\n",
    "import json\n",
    "DATASET_PATH = \"genre_dataset_reduced\"\n",
    "JSON_PATH = \"data.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE*DURATION\n",
    "# storing MFCC and labels in a json file \n",
    "# n_fft = no of samples\n",
    "def save_mfcc(dataset_path,json_path,n_mfcc=13, n_fft=2048,hop_length=512,num_segments = 5):\n",
    "    \n",
    "    # build a dictionary to store data\n",
    "    # creating schema \n",
    "    data = {\n",
    "        \"mapping\":[],# mapping:{\"calssical\",\"blue\"} mapping of classical to 0 and blues to 1\n",
    "                      # genre labelled into numbers \n",
    "        \"mfcc\":[], # [[..],[..],[..]]\n",
    "        \"label\":[] # [0,0,1] 0 = classical, 1 = blues  \n",
    "    }\n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK/num_segments)\n",
    "    expected_num_mfcc_vector_per_segment= math.ceil(num_samples_per_segment/hop_length) #1.2=>2 \n",
    "    \n",
    "    #loop through all the genres \n",
    "    for i,(dirpath ,dirname ,filenames) in enumerate(os.walk(dataset_path)):\n",
    "        \n",
    "        # path to current folder \n",
    "        # dirpath\n",
    "        # path to all folder in crrent path\n",
    "        # dirname\n",
    "        \n",
    "        # ensure that we are not at the root/dataset level \n",
    "        # for first iteration dirpath will give us dataset_path\n",
    "        \n",
    "        if dirpath is not dataset_path:\n",
    "            # save the semantic label \n",
    "            # basically saving classical , blues in mapping\n",
    "            dirpath_components = dirpath.split(\"/\") # if we has dirpth gene/blues this will give us a list => [\"geenre\",\"blues\"]\n",
    "            semantic_label = dirpath_components[-1] # value of last index which is blues\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            #folder level\n",
    "            print(\"\\n processing {}\",format(semantic_label))\n",
    "            \n",
    "            # go through all file in genre folder and proces each for specific genre\n",
    "            for f in filenames:\n",
    "                # laoding the audio file \n",
    "                file_path = os.path.join(dirpath,f)\n",
    "                signal,sr = librosa.load(file_path,sr=SAMPLE_RATE)\n",
    "                \n",
    "                #process segements extractiing mfcc and storing data\n",
    "                for s in range(num_segments):\n",
    "                    start_sample = num_samples_per_segment * s \n",
    "                    finish_sample = start_sample + num_samples_per_segment\n",
    "                    \n",
    "                    # we want to store mfcc for segment if it has expected length\n",
    "                   \n",
    "                    mfcc = librosa.feature.mfcc(signal[start_sample:finish_sample],sr=sr,\n",
    "                                               n_fft=n_fft,\n",
    "                                               n_mfcc=n_mfcc,\n",
    "                                               hop_length = hop_length\n",
    "                                               )\n",
    "                    mfcc = mfcc.T\n",
    "                    if len(mfcc) == expected_num+mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(\"{}, segments:{}\",format(file_path,s))\n",
    "    with open(json_path,\"w\") as fp:\n",
    "        json.dump(data,fp,indent=4) \n",
    "        \n",
    "if __name__ ==\"__main__\":\n",
    "    save_mfcc(DATASET_PATH,JSON_PATH, num_segments = 10)\n",
    "                        \n",
    "    \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: genre_dataset_reduced\\pop\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:1\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:2\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:3\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:4\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:5\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:6\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:7\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:8\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:9\n",
      "genre_dataset_reduced\\pop\\sample.wav, segment:10\n"
     ]
    }
   ],
   "source": [
    "## for understanding refer above one \n",
    "# for experimenting use below correct one \n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "DATASET_PATH = \"genre_dataset_reduced\"\n",
    "JSON_PATH = \"data.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 30 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "\n",
    "\n",
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
    "        :param dataset_path (str): Path to dataset\n",
    "        :param json_path (str): Path to json file used to save MFCCs\n",
    "        :param num_mfcc (int): Number of coefficients to extract\n",
    "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
    "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
    "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # loop through all genre sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "            # process all audio files in genre sub-dir\n",
    "            for f in filenames:\n",
    "\n",
    "\t\t# load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "\n",
    "                    # extract mfcc\n",
    "                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store only mfcc feature with expected number of vectors\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
